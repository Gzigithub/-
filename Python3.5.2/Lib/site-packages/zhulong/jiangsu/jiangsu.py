from threading import Thread

from bs4 import BeautifulSoup
from lmfscrap import web
from lxml import etree
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException

import pandas as pd
from zhulong.util.etl import gg_meta, gg_html, est_html, est_meta
import time

_name_ = 'jiangsu'


def general_template(tb, url, col, f1, f2, conp):
    setting = {
        "url": url,
        "f1": f1,
        "f2": f2,
        "tb": tb,
        "col": col,
        "conp": conp,
        "num": 5,

    }
    m = web()
    m.write(**setting)


def f1(driver, num):
    """
    f1 爬取并翻页  driver： web驱动对象， num：当前爬取的页面
    """
    locator = (By.XPATH, "//tr[@class='ewb-trade-tr'][1]/td/a")
    WebDriverWait(driver, 30).until(EC.visibility_of_element_located(locator))
    time.sleep(0.1)
    val = driver.find_element_by_xpath("//tr[@class='ewb-trade-tr'][1]//a").get_attribute("href")[-50:]
    locator = (By.ID, "divInfoReportPage")
    WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located(locator))
    driver.implicitly_wait(20)
    cnum = int(driver.find_element_by_class_name("pg_maxpagenum").text.split('/')[0])

    if int(num) != cnum:
        time.sleep(0.1)
        driver.find_element_by_class_name("pg_num_input").clear()
        driver.find_element_by_class_name("pg_num_input").send_keys(num)
        driver.find_element_by_class_name("pg_gobtn").click()
        locator = (By.XPATH, "//tr[@class='ewb-trade-tr'][1]/td/a")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located(locator))

        locator = (By.XPATH, "//tr[@class='ewb-trade-tr'][1]//a[not(contains(@href,'%s'))]" % val)
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located(locator))
    data = []
    html = driver.page_source
    body = etree.HTML(html)
    node_list = body.xpath("//tbody[@id='xxList']/tr")
    for node in node_list:
        name = node.xpath("./td/a")[0].text
        ggstart_time = node.xpath("./td")[-1].text
        url = node.xpath("./td/a/@onclick")[0].split('\'')[1]
        temp = [name, ggstart_time, url]
        data.append(temp)
    df = pd.DataFrame(data=data)
    df["info"] = None
    return df


def f2(driver):
    """
        总页数
    """
    locator = (By.ID, "divInfoReportPage")
    WebDriverWait(driver, 20).until(EC.visibility_of_element_located(locator))
    total = int(driver.find_element_by_class_name("pg_maxpagenum").text.split('/')[1])
    driver.implicitly_wait(20)
    driver.quit()
    return int(total)


def f3(driver, url):
    driver.get(url)
    if "76AD6C4FB14C1997E055000000000001" in driver.current_url:
        locator = (By.CLASS_NAME, "ewb-page-wrap")
        WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located(locator))
        flag = 2
    else:
        try:
            locator = (By.CLASS_NAME, "ewb-trade-main")
            WebDriverWait(driver, 20).until(EC.presence_of_element_located(locator))
            flag = False

        except:
            try:
                locator = (By.CLASS_NAME, "article-info")
                WebDriverWait(driver, 20).until(EC.presence_of_element_located(locator))
                flag = True
            except:
                locator = (By.CLASS_NAME, "ewb-page-main ewb-h543")
                WebDriverWait(driver, 20).until(EC.presence_of_element_located(locator))
                flag = 3
    before = len(driver.page_source)
    time.sleep(0.1)
    after = len(driver.page_source)
    i = 0
    while before != after:
        before = len(driver.page_source)
        time.sleep(0.1)
        after = len(driver.page_source)
        i += 1
        if i > 5: break
    page = driver.page_source
    soup = BeautifulSoup(page, 'html.parser')
    if flag:
        div = soup.find('div', class_='ewb-page-wrap')
    elif flag == 2:
        div = soup.find('div', class_='article-info')
    elif flag == 3:
        div = soup.find('div', class_='ewb-page-main ewb-h543')
    else:
        div = soup.find('div', class_='ewb-trade-main')
    return div


def switch(driver, xmtype, ggtype):
    count = 0
    while count < 20:
        try:
            locator = (By.XPATH, "//tr[@class='ewb-trade-tr'][1]/td/a")
            WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located(locator))

            locator = (By.XPATH, "//li//span[@class='wb-tree-tt-bg']/a")
            WebDriverWait(driver, 10).until(EC.visibility_of_all_elements_located(locator))
            driver.find_element_by_xpath("//ul[@id='lefttree']//a[contains(string(),'%s')]" % xmtype).click()

            locator = (By.XPATH, "//ul[@id='lefttree']/li[contains(string(),'%s')]/ul/li/a[contains(string(),'%s')]" % (
                xmtype, ggtype))
            WebDriverWait(driver, 10).until(EC.visibility_of_all_elements_located(locator))

            driver.find_element_by_xpath(
                "//ul[@id='lefttree']/li[contains(string(),'%s')]//ul[@class='wb-tree-sub']//a[contains(string(),'%s')]" % (
                    xmtype, ggtype)).click()
            driver.implicitly_wait(10)
            locator = (By.XPATH, "//tr[@class='ewb-trade-tr'][1]/td")
            WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located(locator))
            break
        except:
            count += 1


def gcjs(f, xmtype, ggtype):
    def wrap(*krg):
        driver = krg[0]
        switch(driver, xmtype, ggtype)
        return f(*krg)

    return wrap


data = [
    # # 工程建设招标公告
    ["gcjs_zhaobiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html", ["name", "ggstart_time", "href", "info"],
     f1, f2],
    # 工程建设中标公告
    ["gcjs_zhongbiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "建设", '中标结果公告'), gcjs(f2, "建设", '中标结果公告')],
    # 工程建设最高限价公示
    ["gcjs_kongzhijia_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "建设", '最高限价'), gcjs(f2, "建设", '最高限价')],
    # 工程建设中标候选
    ["gcjs_zhongbiaohx_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "建设", '候选人'), gcjs(f2, "建设", '候选人')],
    ["gcjs_zishen_weiruwei_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "建设工程", '未入围'), gcjs(f2, "建设工程", '未入围')],

    # 政府采购预告
    ["zfcg_yucai_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html", ["name", "ggstart_time", "href", "info"],
     gcjs(f1, "政府采购", '采购预告'), gcjs(f2, "政府采购", '采购预告')],
    # 政府采购中标公告
    ["zfcg_zhongbiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "政府采购", '成交'), gcjs(f2, "政府采购", '成交')],
    # 政府采购更正公告
    ["zfcg_biangeng_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html", ["name", "ggstart_time", "href", "info"],
     gcjs(f1, "政府采购", '更正'), gcjs(f2, "政府采购", '更正')],
    # 政府采购招标公告
    ["zfcg_zhaobiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html", ["name", "ggstart_time", "href", "info"],
     gcjs(f1, "政府采购", '采购预告'), gcjs(f2, "政府采购", '采购预告')],

    # 交通工程招标
    ["gcjs_jiaotong_zhaobiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "交通工程", '招标'), gcjs(f2, "交通工程", '招标')],
    # 交通工程中标候选人
    ["gcjs_jiaotong_zhongbiaohx_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "交通工程", '中标候选'), gcjs(f2, "交通工程", '中标候选')],
    # 交通工程中标结果
    ["gcjs_jiaotong_zhongbiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"],gcjs(f1, "交通工程", '中标结果'), gcjs(f2, "交通工程", '中标结果')],
    # 交通工程中标结果

    # 水利工程招标公告
    ["gcjs_shuili_zhaobiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "水利工程", '招标'), gcjs(f2, "水利工程", '招标')],
    # 水利工程中标候选人公告
    ["gcjs_shuili_zhongbiaohx_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "水利工程", '中标候选'), gcjs(f2, "水利工程", '中标候选')],
    # 水利工程中标结果公告
    ["gcjs_shuili_zhongbiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "水利工程", '中标结果'), gcjs(f2, "水利工程", '中标结果')],

    # 药品耗材采购公告
    ["yiliao_zhaobiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "药品耗材采购", '采购公告'), gcjs(f2, "药品耗材采购", '采购公告')],
    # 药品耗材成交公告
    ["yiliao_chengjiao_gg", "http://jsggzy.jszwfw.gov.cn/jyxx/tradeInfonew.html",
     ["name", "ggstart_time", "href", "info"], gcjs(f1, "药品耗材采购", '成交公告'), gcjs(f2, "药品耗材采购", '成交公告')],

]


def work(conp, **kwargs):
    est_meta(conp, data=data, diqu="江苏省",**kwargs)
    est_html(conp, f=f3, **kwargs)


if __name__ == "__main__":
    conp=["postgres", "since2015", "192.168.3.171", "jiangsu", "jiangsu"]
    import sys
    arg=sys.argv
    if len(arg) >3:
        work(conp,num=int(arg[1]),total=int(arg[2]),html_total=int(arg[3]))
    elif len(arg) == 2:
        work(conp, html_total=int(arg[1]))
    else:
        work(conp)
