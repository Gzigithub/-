import time

import pandas as pd
import re
from collections import OrderedDict

from lxml import etree
from selenium import webdriver
from bs4 import BeautifulSoup
from lmf.dbv2 import db_write
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException
from selenium.common.exceptions import WebDriverException
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from zhulong.util.etl import add_info, est_meta, est_html, est_tbs

_name_ = "guangan"


def f1(driver, num):
    locator = (By.XPATH, '//*[@id="MoreInfoList1_DataGrid1"]/tbody/tr[1]/td[2]/a')
    val = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator)).text.strip()

    try:
        locator = (By.XPATH, '//*[@id="MoreInfoList1_Pager"]/table/tbody/tr/td[1]/font[3]')
        total = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator)).text.strip()
        cnum = int(total)
    except Exception as e:
        cnum = 1

    # print(cnum)
    if num != cnum:
        driver.execute_script("javascript:__doPostBack('MoreInfoList1$Pager','{}')".format(num))

        locator = (By.XPATH, "//*[@id='MoreInfoList1_DataGrid1']/tbody/tr[1]/td[2]/a[not(contains(string(), '%s'))]" % val)
        WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator))


    page = driver.page_source

    soup = BeautifulSoup(page, 'html.parser')

    tbody = soup.find("table", id="MoreInfoList1_DataGrid1")

    trs = tbody.find_all("tr")
    data = []
    for tr in trs:
        a = tr.find("a")
        try:
            title = a['title'].strip()
        except:
            title = a.text.strip()
        td = tr.find_all("td")[2].text.strip()
        link = "http://www.gasggzy.com" + a["href"]
        tmp = [title, td, link]
        data.append(tmp)


    df = pd.DataFrame(data=data)
    df["info"] = None
    return df


def f2(driver):
    locator = (By.XPATH, '//*[@id="MoreInfoList1_DataGrid1"]/tbody/tr[1]/td[2]/a')
    WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator))
    try:
        locator = (By.XPATH, '//*[@id="MoreInfoList1_Pager"]/table/tbody/tr/td[1]/font[2]')
        total = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator)).text.strip()
        total = int(total)
    except:
        total = 1

    driver.quit()
    return total


def f3(driver, url):
    driver.get(url)
    try:
        time.sleep(1)
        al = driver.switch_to_alert()
        al.accept()
        html = driver.page_source
        if "文件存在问题，请联系管理员!" in html:
            return
    except:
        time.sleep(1)
    html = driver.page_source
    if "Internal Server Error" in html:
        return


    locator = (By.CLASS_NAME, "page")
    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located(locator))


    before = len(driver.page_source)
    time.sleep(0.3)
    after = len(driver.page_source)
    i = 0
    while before != after:
        before = len(driver.page_source)
        time.sleep(0.1)
        after = len(driver.page_source)
        i += 1
        if i > 5: break

    page = driver.page_source

    soup = BeautifulSoup(page, 'html.parser')

    div = soup.find("div", class_="content")
    # div=div.find_all('div',class_='ewb-article')[0]

    return div


def get_data():
    data = []
    # 工程建设部分
    xs = OrderedDict([("市本级", "001"), ("广安区", "002"), ("前锋区", "003"), ("岳池县", "004"),
                      ("武胜县", "005"), ("邻水县", "006"), ("华蓥市", "007")])
    # "http://www.bzggzyjy.gov.cn/bzweb/002/002004/002004001/"
    ggtype = OrderedDict([("zhaobiao", "001"), ("biangeng", "002"), ("zishenjieguo", "003"), ("zhongbiaohx", "004"),
                          ("zhongbiaohxbiangen", "005"), ("zhaobiao_jingzheng", "007")])

    for w2 in xs.keys():
        for w1 in ggtype.keys():
            p1 = "009%s" % (xs[w2])
            p2 = "009%s%s" % (xs[w2], ggtype[w1])
            href = "http://www.gasggzy.com/gasggzy/gcjs/%s/%s/MoreInfo.aspx?CategoryNum=%s" % (p1, p2, p2)
            tb = "gcjs_%s_diqu%s_gg" % (w1, xs[w2])
            if tb == 'gcjs_zhongbiaohxbiangen_diqu003_gg':
                href = "http://www.gasggzy.com/gasggzy/gcjs/009003/009003006/MoreInfo.aspx?CategoryNum=009003006"
            if tb == 'gcjs_zhaobiao_jingzheng_diqu003_gg':
                href = 'http://www.gasggzy.com/gasggzy/gcjs/009003/009003008/MoreInfo.aspx?CategoryNum=009003008'

            col = ["name", "ggstart_time", "href", "info"]
            tmp = [tb, href, col, add_info(f1, {"diqu": w2}), f2]
            data.append(tmp)

    # 政府采购部分
    # 招标
    zbfs = OrderedDict([("zhaobiao", "002"), ("jieguo", "003"), ("biangen", "004"), ("qita", "005")])

    for w2 in xs.keys():
        for w1 in zbfs.keys():
            p1 = "010%s" % (xs[w2])
            p2 = "010%s%s" % (xs[w2], zbfs[w1])
            href = "http://www.gasggzy.com/gasggzy/zfcg/%s/%s/MoreInfo.aspx?CategoryNum=%s" % (p1, p2, p2)
            col = ["name", "ggstart_time", "href", "info"]
            tb = "zfcg_%s_diqu%s_gg" % (w1, xs[w2])
            tmp = [tb, href, col, add_info(f1, {"diqu": w2, "zbfs": w1}), f2]
            data.append(tmp)


    # 国有企业
    ggtype2 = OrderedDict([("zhaobiao", "001"), ("biangen", "002"), ("jieguo", "003"), ("qita", "004")])
    gq = OrderedDict([("工程建设", "001"), ("企业采购", "002")])

    for w2 in gq.keys():
        for w1 in ggtype2.keys():
            p1 = "012%s" % (gq[w2])
            p2 = "012%s%s" % (gq[w2], ggtype2[w1])
            href = "http://www.gasggzy.com/gasggzy/gyqy/%s/%s/MoreInfo.aspx?CategoryNum=%s" % (p1, p2, p2)
            col = ["name", "ggstart_time", "href", "info"]
            tb = "qsydw_%s_lx%s_gg" % (w1, gq[w2])

            tmp = [tb, href, col, add_info(f1, {"leixing": w2}), f2]
            data.append(tmp)

    data1 = data.copy()

    return data1
    # 创建data


data = get_data()


def work(conp, **args):
    est_meta(conp, data=data, diqu="四川省广安市",**args)
    est_html(conp,f=f3,**args)


if __name__ == '__main__':
    work(conp=["postgres", "since2015", "192.168.3.171", "sichuan", "guangan"])


    # est_html(conp=["postgres", "since2015", "127.0.0.1", "shandong", "binzhou"], f=f3)
    # est_tbs(conp=["postgres","since2015","127.0.0.1","shandong","binzhou"],data=data[95:],total=1,num=1)

    # driver=webdriver.Chrome()
    # url = "http://www.gasggzy.com/gasggzy/gyqy/012001/012001001/MoreInfo.aspx?CategoryNum=012001001"
    # driver.get(url)
    # df = f2(driver)
    # print(df)
    #
    # driver=webdriver.Chrome()
    # url = "http://www.gasggzy.com/gasggzy/gyqy/012001/012001001/MoreInfo.aspx?CategoryNum=012001001"
    # driver.get(url)
    # for i in range(1, 16):
    #     df=f1(driver, i)
    #     print(df)

